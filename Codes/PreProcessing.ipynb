{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import shutil\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from skimage.restoration import denoise_nl_means, estimate_sigma\n",
    "from skimage import exposure\n",
    "from skimage.restoration import denoise_wavelet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import shutil\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, Adamax\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the local zip file and extraction directory\n",
    "local_zip = '/content/drive/MyDrive/RA/Knee Osteoarthritis Dataset with Severity Grading.zip'\n",
    "extraction_path = '/content/Knee_Osteoarthritis_Dataset'\n",
    "shutil.unpack_archive(local_zip, extraction_path, 'zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting split-folders\n",
      "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
      "Installing collected packages: split-folders\n",
      "Successfully installed split-folders-0.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install split-folders\n",
    "\n",
    "import splitfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to resize the image\n",
    "def resize_image(image, size=(224, 224)):\n",
    "    return cv2.resize(image, size)\n",
    "\n",
    "# Function to sharpen the image\n",
    "def sharpen_image(image):\n",
    "    kernel = np.array([[0, -1, 0],\n",
    "                       [-1, 5, -1],\n",
    "                       [0, -1, 0]])\n",
    "    return cv2.filter2D(image, -1, kernel)\n",
    "\n",
    "# Function to denoise the image\n",
    "def denoise_image(image):\n",
    "    denoised_image = denoise_wavelet(image, multichannel=True)\n",
    "    denoised_image = (denoised_image * 255).astype(np.uint8)\n",
    "    return denoised_image\n",
    "\n",
    "# Function to apply histogram equalization\n",
    "def equalize_histogram(image):\n",
    "    yuv_img = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)\n",
    "    yuv_img[:, :, 0] = cv2.equalizeHist(yuv_img[:, :, 0])\n",
    "    hist_equalized_img = cv2.cvtColor(yuv_img, cv2.COLOR_YUV2BGR)\n",
    "    return hist_equalized_img\n",
    "\n",
    "# Function to enhance the contrast of the image\n",
    "def enhance_contrast(image):\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "    cl = clahe.apply(l)\n",
    "    limg = cv2.merge((cl, a, b))\n",
    "    return cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "\n",
    "# Function to display images from each step\n",
    "def display_images(images, titles):\n",
    "    fig, axs = plt.subplots(1, len(images), figsize=(20, 5))\n",
    "    for i, (img, title) in enumerate(zip(images, titles)):\n",
    "        axs[i].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        axs[i].set_title(title)\n",
    "        axs[i].axis('off')# Sample image from each class after each preprocessing step\n",
    "def process_and_display_samples(input_dir, class_labels):\n",
    "    for label in class_labels:\n",
    "        class_dir = os.path.join(input_dir, label)\n",
    "        sample_image_path = os.path.join(class_dir, os.listdir(class_dir)[0])\n",
    "        image = cv2.imread(sample_image_path)\n",
    "\n",
    "        # Step 1: Original\n",
    "        original = image\n",
    "\n",
    "        # Step 2: Resize image\n",
    "        resized_image = resize_image(image)\n",
    "\n",
    "        # Step 3: Sharpen image\n",
    "        sharpened_image = sharpen_image(resized_image)\n",
    "\n",
    "        # Step 4: Denoise image\n",
    "        denoised_image = denoise_image(sharpened_image)\n",
    "\n",
    "        # Step 5: Apply histogram equalization\n",
    "        hist_equalized_image = equalize_histogram(denoised_image)\n",
    "\n",
    "        # Step 6: Enhance contrast\n",
    "        contrast_image = enhance_contrast(hist_equalized_image)\n",
    "\n",
    "        # Step 7: Apply CLAHE\n",
    "        clahe_image = contrast_image\n",
    "\n",
    "\n",
    "        # Display images after each step\n",
    "        display_images(\n",
    "            [original, resized_image, sharpened_image, denoised_image, hist_equalized_image,  contrast_image],\n",
    "            ['Original', 'Resized', 'Sharpened', 'Denoised', 'Histogram Equalized', 'Contrast Enhanced']\n",
    "        )\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "train_dir = '/content/Knee_Osteoarthritis_Dataset/Knee Osteoarthritis Dataset with Severity Grading/train'\n",
    "val_dir = '/content/Knee_Osteoarthritis_Dataset/Knee Osteoarthritis Dataset with Severity Grading/val'\n",
    "test_dir = '/content/Knee_Osteoarthritis_Dataset/Knee Osteoarthritis Dataset with Severity Grading/test'\n",
    "class_labels = sorted(os.listdir(train_dir))\n",
    "\n",
    "# Display one sample from each class after each preprocessing step\n",
    "process_and_display_samples(train_dir, class_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess and save images for train, validation, and test datasets\n",
    "output_train_dir = '/content/Knee_Osteoarthritis_Dataset_Preprocessed/train'\n",
    "output_val_dir = '/content/Knee_Osteoarthritis_Dataset_Preprocessed/validation'\n",
    "output_test_dir = '/content/Knee_Osteoarthritis_Dataset_Preprocessed/test'\n",
    "\n",
    "preprocess_and_save_images(train_dir, output_train_dir)\n",
    "preprocess_and_save_images(val_dir, output_val_dir)\n",
    "preprocess_and_save_images(test_dir, output_test_dir)\n",
    "\n",
    "print(\"Preprocessing complete. Preprocessed images are saved in /content/Knee_Osteoarthritis_Dataset_Preprocessed\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
